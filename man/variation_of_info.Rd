% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/information_theory.R
\name{variation_of_info}
\alias{variation_of_info}
\title{Compute the Variation of Information}
\usage{
variation_of_info(p = NULL, base = 2)
}
\arguments{
\item{p}{A matrix of probabilities.}

\item{base}{Which log base to use? Three are most typical. Base 2 for "bits", base \emph{e} for "nats", and base 10 for "hartleys". Defaults to base 2 (bits).}
}
\value{
\code{variation_of_info()} takes a matrix of probabilities as its input. It then returns the matrix's variation of information as its output.
}
\description{
Variation of Information (VOI) is a measure of dissimilarity between two variables. It quantifies how much information is lost or gained when transforming one variable into another. Lower values suggest greater similarity between the variables. Higher values, instead, suggest greater dissimilarity between them.

\code{variation_of_info()} provides a simple way to compute the variation of information in \code{R}.
}
\references{
Shannon, C. E. (1948). A mathematical theory of communication, \emph{The Bell System Technical Journal}. 27(3), pp. 379â€“423.
}
